{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "import transformer_lens.utils as tutils\n",
    "\n",
    "from model import MLP, AutoEncoder\n",
    "from utils import get_freqs, find_similar_decoder_weights, find_similar_encoder_weights\n",
    "from buffer import Buffer\n",
    "from config import Config\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from make_json import make_json, single_neuron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(save_dir='mlps/2023-11-16_19-19-53', device='mps', original_model='gelu-1l', dataset='NeelNanda/c4-code-tokenized-2b', batch_size=2048, buffer_mult=384, num_tokens=3000000000, seq_len=128, layer_idx=0, in_hook='ln2.hook_normalized', out_hook='hook_mlp_out', lr=0.0001, l1_coeff=0.0003, l1_warmup=None, l1_sqrt=False, beta1=0.9, beta2=0.99, weight_decay=0.001, d_hidden_mult=32, d_in=512, act='gelu', leq_renorm=True, per_neuron_coeff=False, model_batch_size=256, buffer_size=786432, buffer_batches=6144)\n",
      "Loaded pretrained model gelu-1l into HookedTransformer\n",
      "Moving model to device:  mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): LayerNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNormPre(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = \"mlps/2023-11-16_19-19-53\" # eg\n",
    "\n",
    "config = Config.from_json(file_path=os.path.join(save_dir, \"cfg.json\"))\n",
    "config.device = 'mps'\n",
    "print(config)\n",
    "\n",
    "original_model = HookedTransformer.from_pretrained(config.original_model)\n",
    "original_model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/slava/safety/ft_exp/.venv/lib/python3.9/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"roneneldan/TinyStories\", split=\"validation\")\n",
    "tokenized_data = tutils.tokenize_and_concatenate(data, original_model.tokenizer, max_length=128)\n",
    "tokenized_data = tokenized_data.shuffle(42)\n",
    "all_tokens = tokenized_data[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling the data\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "torch.Size([786432, 2048]) torch.Size([32768, 2048])\n",
      "self.mid_h.shape torch.Size([32768, 2048])\n",
      "Buffer initialised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.97it/s]\n"
     ]
    }
   ],
   "source": [
    "buffer = Buffer(cfg=config, model=original_model, device=config.device, return_mid=True)\n",
    "\n",
    "model_path = os.path.join(save_dir, \"mlp_final.pt\")\n",
    "\n",
    "model = MLP(cfg=config)\n",
    "model.load_state_dict(torch.load(model_path, map_location=config.device))\n",
    "model.eval()\n",
    "model.to(config.device)\n",
    "\n",
    "freqs = get_freqs(original_model=original_model,\n",
    "                  local_encoder=model,\n",
    "                  all_tokens=buffer.all_tokens,\n",
    "                  cfg=config,\n",
    "                  num_batches=50,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load autoencoder\n",
    "ae_dir = \"autoencoders/clean_armadillo\"\n",
    "ae_config = json.load(open(os.path.join(ae_dir, \"cfg.json\"), \"r\"))\n",
    "ae_model_path = os.path.join(ae_dir, \"autoencoder.pt\")\n",
    "ae = AutoEncoder(\n",
    "    d_hidden=ae_config[\"d_mlp\"] * ae_config[\"expansion_factor\"],\n",
    "    l1_coeff=ae_config[\"l1_coeff\"],\n",
    "    d_in=ae_config[\"d_mlp\"],\n",
    ")\n",
    "ae.load_state_dict(torch.load(ae_model_path, map_location=config.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
